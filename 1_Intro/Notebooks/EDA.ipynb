{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  NOTE*: I have CLEARED all outputs due to the size of the notebook (cannot push the notebook to github with its output). If you want to see the output, please run the notebook yourself."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions answers:  \n",
    "1- 18  \n",
    "2- 46.445295712725304  \n",
    "3- 0.9827547930522406  \n",
    "4- 515  \n",
    "5- 6.986190837370544  \n",
    "6- 7.786409085078911  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    pd.read_parquet(\"../yellow_tripdata_2022-01.parquet\")\n",
    ")\n",
    "data.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Duration and its Standard Deviation (two methods are shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    data\n",
    "    .assign(\n",
    "    duration= lambda df_: df_.tpep_dropoff_datetime - df_.tpep_pickup_datetime,\n",
    "    duration_minutes= lambda df_: df_.duration.dt.total_seconds() / 60\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (data.duration_minutes).std() #it uses np.std under the hood but it is nice to discover all options.  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(data.duration_minutes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Outliers and get durations between [1, 60] minutes.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used plotly to create a box plot since it is more informative about the distribution than the seabor historgram  plot ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "  data\n",
    "  .duration_minutes\n",
    "  .plot.box()  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(data.duration_minutes, label=\"duration in minutes\", kde=True, stat=\"density\", linewidth=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of rides that has duration between [1 and 60] are 98.2% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.query(\"1 <= duration_minutes <= 60.0\")) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    data.query(\"1 <= duration_minutes <= 60.0\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time me we are using DictVectorizer, it takes only strings values in the dictionary.  \n",
    "It has some downsides, like the ordinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict_categories = data.filter(['PULocationID', 'DOLocationID']).astype(str).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer()\n",
    "train = dv.fit_transform(train_dict_categories)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data.duration_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(train, y_train)\n",
    "\n",
    "y_pred = lr.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, train_dict_categories, train, y_train, y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clean_data(filename):\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df = pd.read_parquet(filename)\n",
    "    df = (\n",
    "        df\n",
    "        .assign(\n",
    "        duration= lambda df_: df_.tpep_dropoff_datetime - df_.tpep_pickup_datetime,\n",
    "        duration_minutes= lambda df_: df_.duration.dt.total_seconds() / 60\n",
    "        )\n",
    "        .query(\"1 <= duration_minutes <= 60.0\")\n",
    "        \n",
    "    )\n",
    "    dicts_categorical = df.filter(categorical).astype(str).to_dict(orient='records')\n",
    "    return df, dicts_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val, val_dicts_categories = read_clean_data(\"../yellow_tripdata_2022-02.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = dv.transform(val_dicts_categories)\n",
    "y_val = data_val.duration_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = lr.predict(val)\n",
    "print(mean_squared_error(y_val, y_pred_val, squared=False))\n",
    "del val, val_dicts_categories, lr, dv, y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps_camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
